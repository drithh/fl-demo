{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-08-08 00:17:14,296\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "# from https://github.com/adap/flower/blob/main/examples/simulation-tensorflow/sim.ipynb\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
        "\n",
        "from datasets import Dataset\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "VERBOSE = 0\n",
        "NUM_CLIENTS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    \"\"\"Constructs a simple model architecture suitable for MNIST.\"\"\"\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainset, valset) -> None:\n",
        "        # Create model\n",
        "        self.model = get_model()\n",
        "        self.trainset = trainset\n",
        "        self.valset = valset\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.trainset, epochs=1, verbose=VERBOSE)\n",
        "        return self.model.get_weights(), len(self.trainset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc = self.model.evaluate(self.valset, verbose=VERBOSE)\n",
        "        return loss, len(self.valset), {\"accuracy\": acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from flwr.common import Context\n",
        "\n",
        "def get_client_fn(dataset: FederatedDataset):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(context: Context) -> fl.client.Client:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "\n",
        "        # Extract partition for client with id = cid\n",
        "        client_dataset = dataset.load_partition(int(context.node_id), \"train\")\n",
        "\n",
        "        # Now let's split it into train (90%) and validation (10%)\n",
        "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "        trainset = client_dataset_splits[\"train\"].to_tf_dataset(\n",
        "            columns=\"image\", label_cols=\"label\", batch_size=32\n",
        "        )\n",
        "        valset = client_dataset_splits[\"test\"].to_tf_dataset(\n",
        "            columns=\"image\", label_cols=\"label\", batch_size=64\n",
        "        )\n",
        "\n",
        "        # Create and return client\n",
        "        return FlowerClient(trainset, valset).to_client()\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for mnist contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mnist\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n",
            "2024-08-08 00:17:43,964\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 2148425318.0, 'memory': 4296850638.0, 'node:127.0.0.1': 1.0, 'CPU': 16.0, 'GPU': 1.0, 'accelerator_type:G': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 16 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=21556)\u001b[0m 2024-08-08 00:17:55.686669: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "\u001b[36m(pid=3980)\u001b[0m 2024-08-08 00:18:00.743791: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 25x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m         \n",
            "\u001b[36m(pid=33928)\u001b[0m 2024-08-08 00:18:01.137945: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m 2024-08-08 00:18:14.463184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m c:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m   super().__init__(**kwargs)\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=33876)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33876)\u001b[0m         \u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33876)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33876)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33868)\u001b[0m 2024-08-08 00:18:19.554962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33868)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33796)\u001b[0m c:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\u001b[36m(ClientAppActor pid=33796)\u001b[0m   super().__init__(**kwargs)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m         \u001b[32m [repeated 40x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=29000)\u001b[0m 2024-08-08 00:18:20.008974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=29000)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=29000)\u001b[0m c:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=29000)\u001b[0m   super().__init__(**kwargs)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m         \u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33948)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 100)\n",
            "\u001b[36m(ClientAppActor pid=33804)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33804)\u001b[0m         \u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33804)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33804)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m client_resources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.0\u001b[39m}\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Start simulation\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_client_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactor_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_actor_init_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable GPU growth upon actor init.\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\flwr\\simulation\\app.py:339\u001b[0m, in \u001b[0;36mstart_simulation\u001b[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    344\u001b[0m     log(ERROR, ex)\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\flwr\\server\\server.py:490\u001b[0m, in \u001b[0;36mrun_fl\u001b[1;34m(server, config)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_fl\u001b[39m(\n\u001b[0;32m    486\u001b[0m     server: Server,\n\u001b[0;32m    487\u001b[0m     config: ServerConfig,\n\u001b[0;32m    488\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[0;32m    489\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    495\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SUMMARY]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\flwr\\server\\server.py:143\u001b[0m, in \u001b[0;36mServer.fit\u001b[1;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[0;32m    138\u001b[0m     history\u001b[38;5;241m.\u001b[39madd_metrics_centralized(\n\u001b[0;32m    139\u001b[0m         server_round\u001b[38;5;241m=\u001b[39mcurrent_round, metrics\u001b[38;5;241m=\u001b[39mmetrics_cen\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Evaluate model on a sample of available clients\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m res_fed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_fed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     loss_fed, evaluate_metrics_fed, _ \u001b[38;5;241m=\u001b[39m res_fed\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\flwr\\server\\server.py:184\u001b[0m, in \u001b[0;36mServer.evaluate_round\u001b[1;34m(self, server_round, timeout)\u001b[0m\n\u001b[0;32m    176\u001b[0m log(\n\u001b[0;32m    177\u001b[0m     INFO,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_evaluate: strategy sampled \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m clients (out of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mlen\u001b[39m(client_instructions),\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39mnum_available(),\n\u001b[0;32m    181\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Collect `evaluate` results from all clients participating in this round\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m results, failures \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_clients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m log(\n\u001b[0;32m    191\u001b[0m     INFO,\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate_evaluate: received \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m results and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failures\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mlen\u001b[39m(results),\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mlen\u001b[39m(failures),\n\u001b[0;32m    195\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Aggregate the evaluation results\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\site-packages\\flwr\\server\\server.py:411\u001b[0m, in \u001b[0;36mevaluate_clients\u001b[1;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m    407\u001b[0m     submitted_fs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    408\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(evaluate_client, client_proxy, ins, timeout, group_id)\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m client_proxy, ins \u001b[38;5;129;01min\u001b[39;00m client_instructions\n\u001b[0;32m    410\u001b[0m     }\n\u001b[1;32m--> 411\u001b[0m     finished_fs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Gather results\u001b[39;00m\n\u001b[0;32m    417\u001b[0m results: List[Tuple[ClientProxy, EvaluateRes]] \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\concurrent\\futures\\_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(fs, timeout, return_when)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[0;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[1;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[1;32mc:\\Users\\drith\\miniconda3\\envs\\3.11.9\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Enable GPU growth in your main process\n",
        "enable_tf_gpu_growth()\n",
        "\n",
        "# Download MNIST dataset and partition it\n",
        "mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
        "# Get the whole test set for centralised evaluation\n",
        "centralized_testset = mnist_fds.load_split(\"test\").to_tf_dataset(\n",
        "    columns=\"image\", label_cols=\"label\", batch_size=64\n",
        ")\n",
        "\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.1,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.05,  # Sample 5% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=int(\n",
        "        NUM_CLIENTS * 0.75\n",
        "    ),  # Wait until at least 75 clients are available\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        ")\n",
        "\n",
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=get_client_fn(mnist_fds),\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": enable_tf_gpu_growth  # Enable GPU growth upon actor init.\n",
        "    },\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "flower.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
